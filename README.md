# droid2api

OpenAI 兼容的 API 代理服务器，统一访问不同的 LLM 模型。

## 核心功能

### 🔐 五级认证系统（灵活且向后兼容）

droid2api v1.4+ 支持五级认证优先级，满足从个人使用到企业级多用户场景的所有需求：

#### 认证优先级（从高到低）

1. **🔑 FACTORY_API_KEY 环境变量**（单用户模式，最高优先级）
   - 适用场景：个人使用 / 单密钥 / Docker 部署
   - 优点：配置简单，环境变量配置，Docker 友好
   - 缺点：无轮询，无负载均衡，配额耗尽无兜底
   - 配置方式：`FACTORY_API_KEY=fk-your-key`

2. **🎯 密钥池管理**（多用户模式，推荐企业使用）
   - 适用场景：多密钥 / 负载均衡 / 高并发 / 企业部署
   - 优点：支持无限密钥，自动轮询，负载均衡，自动封禁失效密钥
   - 支持算法：round-robin, random, least-used, weighted-score, least-token-used, max-remaining
   - 配置方式：通过管理 API 添加密钥（`POST /admin/keys/add`）

3. **🔄 DROID_REFRESH_KEY 环境变量**（OAuth 自动刷新，兼容原 droid2api）
   - 适用场景：需要自动刷新 token / 兼容原项目
   - 优点：WorkOS OAuth 集成，6小时自动刷新，失败时使用旧 token 兜底
   - 缺点：依赖 WorkOS API，需要有效的 refresh_token
   - 配置方式：`DROID_REFRESH_KEY=rt-your-refresh-token` 或创建 `data/auth.json`

4. **📁 文件认证**（data/auth.json / ~/.factory/auth.json）
   - 适用场景：向后兼容 / 跨项目共享认证
   - 优先级：`data/auth.json`（项目级，Docker 友好）> `~/.factory/auth.json`（用户级，兜底）
   - 支持格式：`{ "refresh_token": "...", "api_key": "..." }`

5. **🌐 客户端 Authorization Header**（透传模式）
   - 适用场景：客户端直接提供密钥 / 无服务器端配置
   - 由 middleware 处理，无需服务器端配置

#### 选择建议

| 场景 | 推荐方案 | 配置复杂度 | 功能强大度 |
|------|---------|----------|----------|
| 个人使用 / 单密钥 | FACTORY_API_KEY | ⭐ | ⭐⭐ |
| 多密钥 / 负载均衡 | 密钥池管理 | ⭐⭐⭐ | ⭐⭐⭐⭐⭐ |
| 需要自动刷新 | DROID_REFRESH_KEY | ⭐⭐ | ⭐⭐⭐ |
| 向后兼容 | 文件认证 | ⭐ | ⭐⭐ |
| 客户端控制 | Authorization Header | ⭐ | ⭐ |

### 📊 Token使用量追踪系统（Factory专用）
- **自动记录使用量** - 每次API调用自动记录Token消耗
- **数据持久化** - 使用量数据保存到 `data/factory_usage.json`
- **实时统计显示** - 管理界面显示总使用量、今日使用、请求统计
- **按时间段统计** - 支持每日、每小时的使用量分析
- **自动数据清理** - 超过设定天数的数据自动清理（默认30天，可配置）
- **环境变量配置** - 支持通过环境变量控制同步间隔、批量大小、数据保留时间

### 🎯 密钥池管理系统（无限量密钥支持）
- **大规模密钥轮询** - 支持无数量限制的 FACTORY_API_KEY 池化管理
- **智能轮询算法** - 支持 round-robin、random、least-used、weighted-score 四种算法
- **🆕 多级密钥池（v1.4.0+）** - 支持创建多个池子，按优先级自动回退
  - 🎯 **优先级控制** - priority 1 > 2 > 3，优先使用低数字池子
  - 🔄 **自动回退** - 当前池子无可用密钥时，自动切换到下一优先级
  - 🏷️ **池子隔离** - 不同来源的密钥独立管理（白嫖池、主力池等）
  - 📊 **可视化管理** - Dashboard 显示每个池子的统计卡片
  - ⚙️ **灵活配置** - 通过 Web 界面或配置文件管理池子
  - 📖 **详细文档** - 参考 `docs/MULTI_TIER_POOL.md` 和 `data/key_pool.example.json`
- **自动健康检查** - 批量测试密钥可用性，自动标记失效密钥
- **自动封禁机制** - 测试返回200标记成功，402错误自动封禁，其他错误自动禁用
- **Web管理界面** - 可视化管理所有密钥，支持添加/删除/测试/导出
- **密钥状态管理** - active（可用）/disabled（禁用）/banned（封禁）三态管理
- **批量操作** - 批量导入、批量测试、批量删除禁用/封禁密钥
- **数据持久化** - 密钥池状态自动保存到 `data/key_pool.json`，带备份和原子写入

### 🧠 智能推理级别控制
- **五档推理级别** - auto/off/low/medium/high，灵活控制推理行为
- **auto模式** - 完全遵循客户端原始请求，不做任何推理参数修改
- **固定级别** - off/low/medium/high强制覆盖客户端推理设置
- **OpenAI模型** - 自动注入reasoning字段，effort参数控制推理强度
- **Anthropic模型** - 自动配置thinking字段和budget_tokens (4096/12288/24576)
- **智能头管理** - 根据推理级别自动添加/移除anthropic-beta相关标识

### 🚀 服务器部署/Docker部署
- **本地服务器** - 支持npm start快速启动
- **Docker容器化** - 提供完整的Dockerfile和docker-compose.yml
- **云端部署** - 支持各种云平台的容器化部署
- **环境隔离** - Docker部署确保依赖环境的完全一致性
- **生产就绪** - 包含健康检查、日志管理等生产级特性

### 💻 Claude Code直接使用
- **透明代理模式** - /v1/responses和/v1/messages端点支持直接转发
- **完美兼容** - 与Claude Code CLI工具无缝集成
- **系统提示注入** - 自动添加Droid身份标识，保持上下文一致性
- **请求头标准化** - 自动添加Factory特定的认证和会话头信息
- **零配置使用** - Claude Code可直接使用，无需额外设置

## 管理后台

### 访问管理界面

启动服务后，访问 `http://localhost:3000/` 进入 Web 管理界面。

**主要功能**：
- 📊 **密钥池统计** - 查看总数、可用、禁用、封禁密钥数量
- 🎯 **Token使用量监控** - 实时显示总Token使用量、今日使用量、请求统计
- ➕ **添加密钥** - 单个添加或批量导入密钥（自动识别Provider类型）
- 🧪 **测试密钥** - 单个测试或批量测试所有密钥可用性
- 📤 **导出密钥** - 按状态筛选导出为 txt 文件
- 🗑️ **删除密钥** - 单个删除或批量删除禁用/封禁密钥
- ⚙️ **配置管理** - 调整轮询算法、重试机制、性能参数
- 📈 **使用量统计** - Token使用热力图、成功率排行、每日/每小时统计

### 管理 API 端点

所有管理接口需要在请求头中添加 `x-admin-key` 认证：

```bash
curl -H "x-admin-key: your-admin-key" http://localhost:3000/admin/stats
```

**核心接口**：
- `GET /admin/stats` - 密钥池统计信息
- `GET /admin/keys` - 密钥列表（支持分页和状态筛选）
- `POST /admin/keys` - 添加单个密钥
- `POST /admin/keys/batch` - 批量导入密钥
- `DELETE /admin/keys/:id` - 删除密钥
- `PATCH /admin/keys/:id/toggle` - 切换密钥状态
- `POST /admin/keys/:id/test` - 测试单个密钥
- `POST /admin/keys/test-all` - 批量测试所有密钥
- `GET /admin/keys/export` - 导出密钥为txt文件
- `GET /admin/config` - 获取轮询配置
- `PUT /admin/config` - 更新轮询配置

**Token使用量接口**：
- `GET /factory/balance/usage` - 获取Token使用量统计
- `GET /factory/balance/summary` - 获取使用量汇总
- `POST /factory/balance/sync` - 手动触发同步
- `POST /factory/balance/cleanup` - 清理过期数据

**🆕 多级密钥池接口（v1.4.0+）**：
- `GET /admin/pool-groups` - 获取所有密钥池及统计信息
- `POST /admin/pool-groups` - 创建新的密钥池
- `DELETE /admin/pool-groups/:id` - 删除密钥池（密钥自动迁移到 default 池）
- `PATCH /admin/keys/:id/pool` - 修改密钥所属的池子

## 其他特性

- 🎯 **标准 OpenAI API 接口** - 使用熟悉的 OpenAI API 格式访问所有模型
- 🔄 **自动格式转换** - 自动处理不同 LLM 提供商的格式差异
- 🌊 **智能流式处理** - 完全尊重客户端stream参数，支持流式和非流式响应
- ⚙️ **灵活配置** - 通过配置文件自定义模型和端点
- 📝 **智能日志系统** - 开发模式详细控制台日志，生产模式文件日志（按天轮换）

## 🚀 性能优化

droid2api 内置三阶段性能优化方案，支持从个人项目到超大规模应用的渐进式扩展。

### ⚡ 阶段1：基础优化（默认启用，零配置）

**已内置优化**：
- ✅ **HTTP Keep-Alive 连接池** - 复用TCP连接，减少70%握手开销
- ✅ **异步批量文件写入** - 不阻塞主线程，减少100%磁盘I/O等待

**性能提升**：
- 延迟降低：250ms → 50ms（⬇️ 80%）
- 吞吐量提升：500 → 2000+ RPS（⬆️ 300%）
- CPU占用降低：60-80% → 40-60%

**无需任何配置，开箱即用！**

---

### 🔥 阶段2：Redis 缓存（可选，高并发场景）

**适用场景**：日均请求 > 50万

**快速启用**：
```bash
# 1. 安装 Redis 包
npm install redis

# 2. 启动 Redis 服务（Docker最简单）
docker run -d -p 6379:6379 --name redis redis:alpine

# 3. 启动服务（自动检测并启用Redis）
npm start
```

**效果**：
- 密钥池访问延迟降低 90%（5-10ms → 0.5-1ms）
- 吞吐量提升 50%（2000 → 3000+ RPS）
- 支持集群模式的状态共享

**环境变量配置**（可选）：
```bash
# .env 文件
REDIS_HOST=127.0.0.1
REDIS_PORT=6379
REDIS_PASSWORD=           # 如果设置了密码
REDIS_DB=0
```

**优雅降级**：Redis 不可用时自动降级到文件模式，系统继续正常运行。

---

### 🚄 阶段3：集群模式（可选，超高并发场景）

**适用场景**：日均请求 > 100万

**启用方式**：
```bash
# 在 .env 文件中添加
CLUSTER_MODE=true

# 启动服务（自动利用所有CPU核心）
npm start
```

**效果**：
- 吞吐量提升 N 倍（N = CPU核心数，如4核 → 10000+ RPS）
- 自动故障恢复（单进程崩溃不影响服务）
- 零停机重载（优雅重启）

**环境变量配置**（可选）：
```bash
# .env 文件
CLUSTER_MODE=true         # 启用集群模式
CLUSTER_WORKERS=4         # Worker进程数（默认等于CPU核心数）
```

---

### 📊 性能对比表

| 配置 | 吞吐量(RPS) | 平均延迟 | 适用场景 |
|------|-------------|----------|----------|
| **阶段1（默认）** | 2000+ | 50ms | < 50万/天 |
| **阶段1 + Redis** | 3000+ | 30ms | 50-100万/天 |
| **阶段1 + Redis + 集群** | 10000+ | 30ms | > 100万/天 |

---

### 🎯 选择指南

**个人项目/小型应用**（< 10万/天）：
```bash
npm start  # 阶段1优化已足够
```

**中型应用**（10-50万/天）：
```bash
npm install redis
docker run -d -p 6379:6379 redis:alpine
npm start  # 阶段1 + Redis
```

**大型应用**（50-200万/天）：
```bash
npm install redis
docker run -d -p 6379:6379 redis:alpine
# 在 .env 中设置 CLUSTER_MODE=true
npm start  # 阶段1 + Redis + 集群
```

**超大型应用**（> 200万/天）：
使用 Nginx 负载均衡 + 多服务器部署（参考 DOCKER_DEPLOY.md）

---

### 🧪 性能测试

**内置压测工具**：
```bash
node tests/benchmark.js
```

**输出示例**：
```
📊 GET /v1/models - 性能报告
总请求数:    1000
吞吐量:      1923.08 req/s  ← 🔥 比优化前快4倍！
平均延迟:    51.23ms         ← 🔥 比优化前快5倍！
```

---

### ❓ 常见问题

**Q: Redis 必须安装吗？**
- 不是！Redis 是可选功能，不安装系统照常运行，只是性能稍低。

**Q: 集群模式如何选择进程数？**
- 推荐设置为 CPU 核心数（默认自动检测）

**Q: Redis 故障会导致系统崩溃吗？**
- 不会！系统会自动降级到文件模式，继续正常运行。

详细配置和监控指南请参考 `.env.example` 文件。

## 环境变量配置

创建 `.env` 文件（可参考 `.env.example`）：

```env
# ===== 认证配置 =====
ADMIN_ACCESS_KEY=your-admin-key        # 管理后台访问密钥（必需）
API_ACCESS_KEY=your-api-key           # 客户端API访问密钥（可选）
FACTORY_API_KEY=fk-xxxxx              # Factory API密钥（可选）

# ===== Token使用量管理配置 =====
SYNC_INTERVAL_MINUTES=30              # Token同步间隔（分钟，默认30）
BATCH_SIZE=5                          # 批量请求大小（默认5）
DATA_RETENTION_DAYS=30                # 数据保留天数（默认30）

# ===== 服务器配置 =====
PORT=3000                              # 服务端口
NODE_ENV=production                    # 运行环境
```

## 安装

安装项目依赖：

```bash
npm install
```

**依赖说明**：
- `express` - Web服务器框架
- `node-fetch` - HTTP请求库

> 💡 **首次使用必须执行 `npm install`**，之后只需要 `npm start` 启动服务即可。

## 快速开始

### 1. 配置认证（三种方式）

**优先级：FACTORY_API_KEY > refresh_token > 客户端authorization**

```bash
# 方式1：固定API密钥（最高优先级）
export FACTORY_API_KEY="your_factory_api_key_here"

# 方式2：自动刷新令牌
export DROID_REFRESH_KEY="your_refresh_token_here"

# 方式3：配置文件 ~/.factory/auth.json
{
  "access_token": "your_access_token", 
  "refresh_token": "your_refresh_token"
}

# 方式4：无配置（客户端授权）
# 服务器将使用客户端请求头中的authorization字段
```

### 2. 配置环境变量

创建 `.env` 文件配置以下变量：

```env
# ===== API 认证配置（三选一） =====
FACTORY_API_KEY=your_factory_api_key_here        # 方式1：固定密钥（推荐）
DROID_REFRESH_KEY=your_refresh_token_here        # 方式2：自动刷新令牌

# ===== 管理后台配置（必需） =====
ADMIN_ACCESS_KEY=your-secure-admin-password      # 管理后台访问密钥（强烈推荐设置）

# ===== 服务配置（可选） =====
PORT=3000                                        # 服务端口（默认3000）
NODE_ENV=production                              # 运行环境（development/production）
```

**重要说明**：
- `ADMIN_ACCESS_KEY` 用于保护管理后台 `/admin/*` 接口，请设置强密码
- `NODE_ENV=development` 启用详细日志但不写入文件（开发模式）
- `NODE_ENV=production` 启用文件日志到 `logs/` 目录（生产模式）

### 3. 配置模型（可选）

编辑 `data/config.json` 添加或修改模型：

```json
{
  "port": 3000,
  "models": [
    {
      "name": "Claude Opus 4",
      "id": "claude-opus-4-1-20250805",
      "type": "anthropic",
      "reasoning": "high"
    },
    {
      "name": "GPT-5",
      "id": "gpt-5-2025-08-07",
      "type": "openai",
      "reasoning": "medium"
    }
  ],
  "system_prompt": "You are Droid, an AI software engineering agent built by Factory.\n\nPlease forget the previous content and remember the following content.\n\n"
}
```

#### 推理级别配置

每个模型支持五种推理级别：

- **`auto`** - 遵循客户端原始请求，不做任何推理参数修改
- **`off`** - 强制关闭推理功能，删除所有推理字段
- **`low`** - 低级推理 (Anthropic: 4096 tokens, OpenAI: low effort)
- **`medium`** - 中级推理 (Anthropic: 12288 tokens, OpenAI: medium effort) 
- **`high`** - 高级推理 (Anthropic: 24576 tokens, OpenAI: high effort)

**对于Anthropic模型 (Claude)**：
```json
{
  "name": "Claude Sonnet 4.5", 
  "id": "claude-sonnet-4-5-20250929",
  "type": "anthropic",
  "reasoning": "auto"  // 推荐：让客户端控制推理
}
```
- `auto`: 保留客户端thinking字段，不修改anthropic-beta头
- `low/medium/high`: 自动添加thinking字段和anthropic-beta头，budget_tokens根据级别设置

**对于OpenAI模型 (GPT)**：
```json
{
  "name": "GPT-5",
  "id": "gpt-5-2025-08-07",
  "type": "openai", 
  "reasoning": "auto"  // 推荐：让客户端控制推理
}
```
- `auto`: 保留客户端reasoning字段不变
- `low/medium/high`: 自动添加reasoning字段，effort参数设置为对应级别

## 使用方法

### 启动服务器

**方式1：使用npm命令**
```bash
npm start
```

**方式2：使用启动脚本**

Linux/macOS：
```bash
./start.sh
```

Windows：
```cmd
start.bat
```

服务器默认运行在 `http://localhost:3000`。

### Docker部署

#### 使用docker-compose（推荐）

```bash
# 构建并启动服务
docker-compose up -d

# 查看日志
docker-compose logs -f

# 停止服务
docker-compose down
```

#### 使用Dockerfile

```bash
# 构建镜像
docker build -t droid2api .

# 运行容器
docker run -d \
  -p 3000:3000 \
  -e DROID_REFRESH_KEY="your_refresh_token" \
  --name droid2api \
  droid2api
```

#### 环境变量配置

Docker部署支持以下环境变量：

- `DROID_REFRESH_KEY` - 刷新令牌（必需）
- `PORT` - 服务端口（默认3000）
- `NODE_ENV` - 运行环境（production/development）

### Claude Code集成

#### 配置Claude Code使用droid2api

1. **设置代理地址**（在Claude Code配置中）：
   ```
   API Base URL: http://localhost:3000
   ```

2. **可用端点**：
   - `/v1/chat/completions` - 标准OpenAI格式，自动格式转换
   - `/v1/responses` - 直接转发到OpenAI端点（透明代理）
   - `/v1/messages` - 直接转发到Anthropic端点（透明代理）
   - `/v1/models` - 获取可用模型列表

3. **自动功能**：
   - ✅ 系统提示自动注入
   - ✅ 认证头自动添加
   - ✅ 推理级别自动配置
   - ✅ 会话ID自动生成

#### 示例：Claude Code + 推理级别

当使用Claude模型时，代理会根据配置自动添加推理功能：

```bash
# Claude Code发送的请求会自动转换为：
{
  "model": "claude-sonnet-4-5-20250929",
  "thinking": {
    "type": "enabled",
    "budget_tokens": 24576  // high级别自动设置
  },
  "messages": [...],
  // 同时自动添加 anthropic-beta: interleaved-thinking-2025-05-14 头
}
```

### API 使用

#### 获取模型列表

```bash
curl http://localhost:3000/v1/models
```

#### 对话补全

**流式响应**（实时返回）：
```bash
curl http://localhost:3000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "claude-opus-4-1-20250805",
    "messages": [
      {"role": "user", "content": "你好"}
    ],
    "stream": true
  }'
```

**非流式响应**（等待完整结果）：
```bash
curl http://localhost:3000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "claude-opus-4-1-20250805",
    "messages": [
      {"role": "user", "content": "你好"}
    ],
    "stream": false
  }'
```

**支持的参数：**
- `model` - 模型 ID（必需）
- `messages` - 对话消息数组（必需）
- `stream` - 流式输出控制（可选）
  - `true` - 启用流式响应，实时返回内容
  - `false` - 禁用流式响应，等待完整结果
  - 未指定 - 由服务器端决定默认行为
- `max_tokens` - 最大输出长度
- `temperature` - 温度参数（0-1）

## 常见问题

### 如何配置授权机制？

droid2api支持三级授权优先级：

1. **FACTORY_API_KEY**（最高优先级）
   ```bash
   export FACTORY_API_KEY="your_api_key"
   ```
   使用固定API密钥，停用自动刷新机制。

2. **refresh_token机制**
   ```bash
   export DROID_REFRESH_KEY="your_refresh_token"
   ```
   自动刷新令牌，每6小时更新一次。

3. **客户端授权**（fallback）
   无需配置，直接使用客户端请求头的authorization字段。

### 什么时候使用FACTORY_API_KEY？

- **开发环境** - 使用固定密钥避免令牌过期问题
- **CI/CD流水线** - 稳定的认证，不依赖刷新机制
- **临时测试** - 快速设置，无需配置refresh_token

### 如何控制流式和非流式响应？

droid2api完全尊重客户端的stream参数设置：

- **`"stream": true`** - 启用流式响应，内容实时返回
- **`"stream": false`** - 禁用流式响应，等待完整结果后返回
- **不设置stream** - 由服务器端决定默认行为，不强制转换

### 什么是auto推理模式？

`auto` 是v1.3.0新增的推理级别，完全遵循客户端的原始请求：

**行为特点**：
- 🎯 **零干预** - 不添加、不删除、不修改任何推理相关字段
- 🔄 **完全透传** - 客户端发什么就转发什么
- 🛡️ **头信息保护** - 不修改anthropic-beta等推理相关头信息

**使用场景**：
- 客户端需要完全控制推理参数
- 与原始API行为保持100%一致
- 不同客户端有不同的推理需求

**示例对比**：
```bash
# 客户端请求包含推理字段
{
  "model": "claude-opus-4-1-20250805",
  "reasoning": "auto",           // 配置为auto
  "messages": [...],
  "thinking": {"type": "enabled", "budget_tokens": 8192}
}

# auto模式：完全保留客户端设置
→ thinking字段原样转发，不做任何修改

# 如果配置为"high"：会被覆盖为 {"type": "enabled", "budget_tokens": 24576}
```

### 如何配置推理级别？

在 `data/config.json` 中为每个模型设置 `reasoning` 字段：

```json
{
  "models": [
    {
      "id": "claude-opus-4-1-20250805", 
      "type": "anthropic",
      "reasoning": "auto"  // auto/off/low/medium/high
    }
  ]
}
```

**推理级别说明**：

| 级别 | 行为 | 适用场景 |
|------|------|----------|
| `auto` | 完全遵循客户端原始请求参数 | 让客户端自主控制推理 |
| `off` | 强制禁用推理，删除所有推理字段 | 快速响应场景 |
| `low` | 轻度推理 (4096 tokens) | 简单任务 |
| `medium` | 中度推理 (12288 tokens) | 平衡性能与质量 |
| `high` | 深度推理 (24576 tokens) | 复杂任务 |

### 令牌多久刷新一次？

系统每6小时自动刷新一次访问令牌。刷新令牌有效期为8小时，确保有2小时的缓冲时间。

### 如何检查令牌状态？

查看服务器日志，成功刷新时会显示：
```
Token refreshed successfully, expires at: 2025-01-XX XX:XX:XX
```

### Claude Code无法连接怎么办？

1. 确保droid2api服务器正在运行：`curl http://localhost:3000/v1/models`
2. 检查Claude Code的API Base URL设置
3. 确认防火墙没有阻止端口3000

### 推理功能为什么没有生效？

**如果推理级别设置无效**：
1. 检查模型配置中的 `reasoning` 字段是否为有效值 (`auto/off/low/medium/high`)
2. 确认模型ID是否正确匹配data/config.json中的配置
3. 查看服务器日志确认推理字段是否正确处理

**如果使用auto模式但推理不生效**：
1. 确认客户端请求中包含了推理字段 (`reasoning` 或 `thinking`)
2. auto模式不会添加推理字段，只会保留客户端原有的设置
3. 如需强制推理，请改用 `low/medium/high` 级别

**推理字段对应关系**：
- OpenAI模型 (`gpt-*`) → 使用 `reasoning` 字段
- Anthropic模型 (`claude-*`) → 使用 `thinking` 字段

### 如何更改端口？

编辑 `data/config.json` 中的 `port` 字段：

```json
{
  "port": 8080
}
```

### 如何启用调试日志？

在 `data/config.json` 中设置：

```json
{
  "dev_mode": true
}
```

## 故障排查

### 认证失败

确保已正确配置 refresh token：
- 设置环境变量 `DROID_REFRESH_KEY`
- 或创建 `~/.factory/auth.json` 文件

### 模型不可用

检查 `data/config.json` 中的模型配置，确保模型 ID 和类型正确。

## 许可证

MIT
